{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('districtwise-cyber-crimes-2017-onwards.csv')\n",
    "\n",
    "# Remove irrelevant columns\n",
    "irrelevant_columns = ['id', 'state_code', 'district_name', 'district_code', 'registration_circles']\n",
    "data = data.drop(columns=irrelevant_columns)\n",
    "\n",
    "# Fill missing values\n",
    "data.fillna(0, inplace=True)\n",
    "\n",
    "# Aggregating data by state and year\n",
    "data_state_year = data.groupby(['state_name', 'year']).sum().reset_index()\n",
    "\n",
    "# Features and targets for SVR\n",
    "crime_columns = data.columns[3:]  # Selecting all crime columns starting from index 3\n",
    "\n",
    "def predict_crimes(state_data, state_name, scaler_X, scaler_y):\n",
    "    \"\"\"Train SVR and predict crimes till 2030 for a given state.\"\"\"\n",
    "    future_years = np.array([2023, 2024, 2025, 2026, 2027, 2028, 2029, 2030]).reshape(-1, 1)\n",
    "    predictions = []\n",
    "\n",
    "    for crime in crime_columns:\n",
    "        # Prepare the data\n",
    "        X = np.array(state_data['year']).reshape(-1, 1)\n",
    "        y = np.array(state_data[crime])\n",
    "\n",
    "        # Scale the data\n",
    "        X_scaled = scaler_X.fit_transform(X)\n",
    "        y_scaled = scaler_y.fit_transform(y.reshape(-1, 1)).flatten()\n",
    "\n",
    "        # Train SVR\n",
    "        model = SVR(kernel='rbf', C=100, gamma=0.1, epsilon=0.1)\n",
    "        model.fit(X_scaled, y_scaled)\n",
    "\n",
    "        # Predict future\n",
    "        future_X_scaled = scaler_X.transform(future_years)\n",
    "        predicted_scaled = model.predict(future_X_scaled)\n",
    "        predicted = scaler_y.inverse_transform(predicted_scaled.reshape(-1, 1)).flatten()\n",
    "        predictions.append(predicted)\n",
    "\n",
    "    # Organizing predictions\n",
    "    future_predictions = pd.DataFrame(\n",
    "        np.array(predictions).T,\n",
    "        columns=crime_columns,\n",
    "        index=future_years.flatten()\n",
    "    )\n",
    "    future_predictions.reset_index(inplace=True)\n",
    "    future_predictions.rename(columns={'index': 'year'}, inplace=True)\n",
    "    future_predictions['state_name'] = state_name\n",
    "\n",
    "    return future_predictions\n",
    "\n",
    "# Process for each state\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "predictions_all_states = []\n",
    "\n",
    "for state_name in data_state_year['state_name'].unique():\n",
    "    state_data = data_state_year[data_state_year['state_name'] == state_name]\n",
    "    state_predictions = predict_crimes(state_data, state_name, scaler_X, scaler_y)\n",
    "    predictions_all_states.append(state_predictions)\n",
    "\n",
    "# Combine all state predictions\n",
    "future_data = pd.concat(predictions_all_states, ignore_index=True)\n",
    "\n",
    "# Adding top 5 crimes for each year and state\n",
    "def get_top_crimes(row):\n",
    "    row_sorted = row[crime_columns].sort_values(ascending=False)\n",
    "    return ', '.join(row_sorted.index[:5])\n",
    "\n",
    "future_data['top_5_crimes'] = future_data.apply(get_top_crimes, axis=1)\n",
    "\n",
    "# Combine future predictions with original data\n",
    "final_data = pd.concat([data_state_year, future_data], ignore_index=True)\n",
    "\n",
    "# Calculate total crimes in each year\n",
    "yearly_totals = final_data.groupby('year')[crime_columns].sum()\n",
    "yearly_totals['total_crimes'] = yearly_totals.sum(axis=1)\n",
    "\n",
    "# Calculate top crimes for each year\n",
    "def get_yearly_top_crimes(row):\n",
    "    sorted_crimes = row.sort_values(ascending=False)\n",
    "    return ', '.join(sorted_crimes.index[:5])\n",
    "\n",
    "yearly_totals['top_crimes'] = yearly_totals.apply(get_yearly_top_crimes, axis=1)\n",
    "\n",
    "# Calculate top states for each year\n",
    "yearly_state_totals = final_data.groupby(['year', 'state_name'])['total_offences_under_ip'].sum().reset_index()\n",
    "def get_top_states(year):\n",
    "    year_data = yearly_state_totals[yearly_state_totals['year'] == year]\n",
    "    top_states = year_data.sort_values(by='total_offences_under_ip', ascending=False).head(5)\n",
    "    return ', '.join(top_states['state_name'])\n",
    "\n",
    "yearly_totals['top_states'] = yearly_totals.index.map(get_top_states)\n",
    "\n",
    "# Save the aggregated yearly data for Tableau\n",
    "output_path = 'yearly_crime_analysis.csv'\n",
    "yearly_totals.to_csv(output_path, index=True)\n",
    "\n",
    "print(f\"Yearly crime analysis saved to {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
